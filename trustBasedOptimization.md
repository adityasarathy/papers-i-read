[Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477)
============================================

TL;DR: The success of	neural	networks	in	supervised	learning	relies	on	the	fact	that	learning	reduces	to	a	nonlinear	optimization	problem. An improved understanding of monotonic behavior can fully wield the power of non-linear function approximators in RL. The authors aim to achieve monotonic policy improvement, both in theory and practice. A good policy should be applicable to arbitrary policy parameterization and should provide guidance about step-size selection.



