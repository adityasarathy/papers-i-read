[Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
=================================================
####Motivation:
Seq2Seq addresses problems such as machine translation, language modeling and speech recognition. At a high level, the model takes in a sequence of inputs, looks at each element of the sequence and tries to predict the next element. Language models are generative -- once trained, they can be used to generate sequnences of information by feeding their previous outputs back into the model.

####TL;DR:
